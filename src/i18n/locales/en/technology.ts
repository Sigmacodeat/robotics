const technology = {
  // Tech KPIs used for the 4 cards under the title
  kpi: {
    uptime: '99.99%',
    latencyP95: '<10 ms',
    buildTime: '~8 min',
    trl: '3 → 8 (2030)'
  },
  paragraphs: [
    'AI framework: SigmaCode AI agent system, extended for robotics (behavior control, orchestration).',
    'App store: cloud‑based microservice architecture with payments & licensing.',
    'Safety & compliance: implementation of EU AI Act & ISO 13482, auditability & guardrails.',
    'IP strategy: protection of framework, safety layer & orchestration (patents/trademarks).',
  ],
  stack: [
    "Python, ROS2 (rclcpp/rclpy), Nav2/MoveIt",
    "PyTorch/JAX, diffusion policies, VLM/VLA (OpenVLA, RT‑X)",
    "Isaac Lab/Sim, CuOpt, Triton Inference + TensorRT‑LLM",
    "LangGraph/agents, gRPC/event streams, Kafka/Redpanda",
    "Cloud‑native microservices (K8s), feature flags, canary",
  ],
  points: [
    "Humanoid locomotion & balance: MPC, WBC and learned policies for robust walking, stairs/ladders, recovery steps",
    "Whole‑body manipulation: bimanual grasping, force/impedance control, hand‑eye coordination; VLM‑backed 3D perception (RGB‑D/LiDAR)",
    "Sim‑to‑real for humanoids: physics‑accurate simulation (MuJoCo/Isaac) + domain randomization/diffusion policies",
    "Safety & HRI: zone/contact‑force guardrails, collaborative trajectories, audit logs & provenance",
    "Edge execution <10ms: TensorRT/XLA/ONNX Runtime, zero‑copy pipelines on ARM/x86 GPUs; fleet‑wide versioning via policy hub",
  ],
  // Target hardware (humanoids) – shortlist for procurement & integration
  hardwareTargets: [
    "Tesla – Optimus: humanoid; focus on industrial/everyday tasks; advanced development; source: https://www.tesla.com/",
    "Figure – 02: humanoid; AI collaboration (OpenAI); active development; source: https://figure.ai/",
    "Agility – Digit: bipedal; logistics focus; source: https://agilityrobotics.com/",
  ],
  // Sensors & compute – reference stack
  sensorsCompute: [
    "RGB‑D (e.g., Luxonis OAK‑D) + hand‑eye calibration",
    "LiDAR (Livox/Ouster) + 3D fusion (TSDF/Gaussian)",
    "Event cameras (proprio/high‑speed grasping)",
    "Tactile/FT sensors (BioTac, ATI Mini45) for grip evals",
    "Compute: NVIDIA Jetson Orin (Nano/AGX) + edge RTX; NVLink streaming",
    "End effectors: Robotiq/Schunk with force control, quick‑change",
  ],
  // Curated datasets & licensing notes
  datasets: [
    "Open‑X Embodiment – multi‑task manipulation; source: https://robotics-transformer-x.github.io/",
    "DROID – large‑scale robot imitation dataset; source: https://droid-dataset.github.io/",
    "Ego4D – 3,670h, 923 participants, 74 locations, 9 countries; egocentric perception/HRI; source: https://ego4d-data.org/",
    "EPIC‑KITCHENS – kitchen interactions (hand‑object); source: https://epic-kitchens.github.io/",
    "RT‑X/RT‑2 – repos/papers; reference policies & data domains; source: https://robotics-transformer-x.github.io/",
    "Isaac/MuJoCo sim assets – sim2real & domain randomization; sources: https://developer.nvidia.com/isaac, https://mujoco.org/",
  ],
  // Integration plan (short)
  integrationPlan: [
    "Shortlist & procurement: 1–2 humanoid platforms (pilot)",
    "ROS2 adapters/drivers: teleop, state estimation, safety E‑stop",
    "Perception: RGB‑D/LiDAR fusion, VLM assists, 6D poses",
    "Manipulation: WBC/MPC + diffusion/imitation skills (grasp/carry)",
    "Safety/HRI evals, canary rollouts, tele‑assist; fleet versioning",
  ],
  // Comparison and references exist below
  // Roadmap
  roadmap: [
    "2025: perception/VLA baselines, Isaac Sim environments",
    "2026: integration of humanoid robots, live demonstrator",
    "2027: behaviors/everyday scenarios, diffusion/IL base models",
    "2028: app store beta + developer SDK (third‑party skills)",
    "2029: RaaS pilots, fleet learning & monitoring",
    "2030: certification, EU launch",
  ],
  // Timeline phases
  timelinePhases: [
    { period: "2025 – Foundations & prototyping", items: ["AI framework, ROS2 integration, sim demonstrator"] },
    { period: "2026 – Integration & demo", items: ["Humanoid demonstrator, end‑to‑end tests"] },
    { period: "2027 – Behaviors & everyday", items: ["Everyday scenarios (grasping/assist), base models"] },
    { period: "2028 – App store beta", items: ["Developer SDK, billing/licensing"] },
    { period: "2029 – RaaS pilots", items: ["Fleet management, monitoring, updates"] },
    { period: "2030 – Certification & EU launch", items: ["CE/safety audits, market entry EU"] },
  ],
  // Work packages
  workPackages: [
    { id: "WP1", name: "Software framework for robot AI", timeline: "2025", deliverables: ["API docs", "v0.1 demo (motion+language)"] },
    { id: "WP2", name: "Acquisition & integration of humanoid robots", timeline: "2026", deliverables: ["Integration study", "Live demo Q2 2026"] },
    { id: "WP3", name: "AI behavior modeling", timeline: "2027", deliverables: ["Datasets", "v1.0 base models"] },
    { id: "WP4", name: "Platform 'Robot App Store'", timeline: "2028", deliverables: ["Beta platform", "Developer SDK"] },
    { id: "WP5", name: "Robots‑as‑a‑Service (RaaS)", timeline: "2029", deliverables: ["SaaS dashboard", "3 pilot projects"] },
    { id: "WP6", name: "Scaling & certification", timeline: "2030", deliverables: ["Certification docs", "EU launch"] },
  ],
  safetyCompliancePoints: [
    "EU AI Act implementation, audit logs, provenance",
    "Safety guardrails (zones/contact force), HRI risk assessment",
    "Canary rollouts, tele‑assist, observability",
  ],
  standardsList: [
    "ISO 13482 (personal care robots)",
    "ISO 10218 / ISO/TS 15066 (collaborative robotics)",
    "CE directives & technical documentation",
  ],
  trl: { today: 3, target: "7–8" },
  compare: [
    ["Locomotion/balance", "Gait libs + heuristics, limited terrain", "MPC/WBC + learned recovery; robust terrain adaptation"],
    ["Manipulation", "Single‑arm, fixed sequences", "Bimanual, whole‑body, force control; learned skills"],
    ["Perception", "2D/marker‑based", "VLM + 3D representations, open vocabularies"],
    ["Deployment", "Monolithic releases", "Policy hub, canary, tele‑assist, fleet learning"],
    ["Safety/HRI", "Basic E‑stop/fencing", "Zone/contact‑force limits, collaborative trajectories, CE artifacts"],
    ["Platform", "Closed stacks", "App store/RaaS + SDK, third‑party skills, billing/licensing"],
  ],
  references: [
    "[1] EU AI Act & CE guidelines – safety management, technical documentation",
    "[2] Whole‑body control & MPC – humanoid locomotion/balance (ETH/CMU/Google Robotics)",
    "[3] VLMs & 3D perception for robotics – OpenVLA, RT‑X, GPV",
    "[4] Sim2Real for humanoids – diffusion policies, domain randomization (Stanford/Google)",
    "[5] MLOps/provenance – model cards, data sheets, audit trails",
  ],
} as const;

export default technology;

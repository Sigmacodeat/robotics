// Auto-generated by sort-i18n-ts.js
// File: src/i18n/locales/en/technology.ts
const data = {
  "compare": [
    [
      "Locomotion/balance",
      "Gait libs + heuristics, limited terrain",
      "MPC/WBC + learned recovery; robust terrain adaptation"
    ],
    [
      "Manipulation",
      "Single‑arm, fixed sequences",
      "Bimanual, whole‑body, force control; learned skills"
    ],
    [
      "Perception",
      "2D/marker‑based",
      "VLM + 3D representations, open vocabularies"
    ],
    [
      "Deployment",
      "Monolithic releases",
      "Policy hub, canary, tele‑assist, fleet learning"
    ],
    [
      "Safety/HRI",
      "Basic E‑stop/fencing",
      "Zone/contact‑force limits, collaborative trajectories, CE artifacts"
    ],
    [
      "Platform",
      "Closed stacks",
      "App store/RaaS + SDK, third‑party skills, billing/licensing"
    ]
  ],
  "datasets": [
    "Open‑X Embodiment – multi‑task manipulation; source: https://robotics-transformer-x.github.io/",
    "DROID – large‑scale robot imitation dataset; source: https://droid-dataset.github.io/",
    "Ego4D – 3,670h, 923 participants, 74 locations, 9 countries; egocentric perception/HRI; source: https://ego4d-data.org/",
    "EPIC‑KITCHENS – kitchen interactions (hand‑object); source: https://epic-kitchens.github.io/",
    "RT‑X/RT‑2 – repos/papers; reference policies & data domains; source: https://robotics-transformer-x.github.io/",
    "Isaac/MuJoCo sim assets – sim2real & domain randomization; sources: https://developer.nvidia.com/isaac, https://mujoco.org/"
  ],
  "hardwareTargets": [
    "Tesla – Optimus: humanoid; focus on industrial/everyday tasks; advanced development; source: https://www.tesla.com/",
    "Figure – 02: humanoid; AI collaboration (OpenAI); active development; source: https://figure.ai/",
    "Agility – Digit: bipedal; logistics focus; source: https://agilityrobotics.com/"
  ],
  "integrationPlan": [
    "Shortlist & procurement: 1–2 humanoid platforms (pilot)",
    "ROS2 adapters/drivers: teleop, state estimation, safety E‑stop",
    "Perception: RGB‑D/LiDAR fusion, VLM assists, 6D poses",
    "Manipulation: WBC/MPC + diffusion/imitation skills (grasp/carry)",
    "Safety/HRI evals, canary rollouts, tele‑assist; fleet versioning"
  ],
  "kpi": {
    "buildTime": "~8 min",
    "latencyP95": "<10 ms",
    "trl": "3 → 8 (2030)",
    "uptime": "99.99%"
  },
  "paragraphs": [
    "AI framework: SigmaCode AI agent system, extended for robotics (behavior control, orchestration).",
    "App store: cloud‑based microservice architecture with payments & licensing.",
    "Safety & compliance: implementation of EU AI Act & ISO 13482, auditability & guardrails.",
    "IP strategy: protection of framework, safety layer & orchestration (patents/trademarks)."
  ],
  "points": [
    "Humanoid locomotion & balance: MPC, WBC and learned policies for robust walking, stairs/ladders, recovery steps",
    "Whole‑body manipulation: bimanual grasping, force/impedance control, hand‑eye coordination; VLM‑backed 3D perception (RGB‑D/LiDAR)",
    "Sim‑to‑real for humanoids: physics‑accurate simulation (MuJoCo/Isaac) + domain randomization/diffusion policies",
    "Safety & HRI: zone/contact‑force guardrails, collaborative trajectories, audit logs & provenance",
    "Edge execution <10ms: TensorRT/XLA/ONNX Runtime, zero‑copy pipelines on ARM/x86 GPUs; fleet‑wide versioning via policy hub"
  ],
  "references": [
    "[1] EU AI Act & CE guidelines – safety management, technical documentation",
    "[2] Whole‑body control & MPC – humanoid locomotion/balance (ETH/CMU/Google Robotics)",
    "[3] VLMs & 3D perception for robotics – OpenVLA, RT‑X, GPV",
    "[4] Sim2Real for humanoids – diffusion policies, domain randomization (Stanford/Google)",
    "[5] MLOps/provenance – model cards, data sheets, audit trails"
  ],
  "roadmap": [
    "2025: perception/VLA baselines, Isaac Sim environments",
    "2026: integration of humanoid robots, live demonstrator",
    "2027: behaviors/everyday scenarios, diffusion/IL base models",
    "2028: app store beta + developer SDK (third‑party skills)",
    "2029: RaaS pilots, fleet learning & monitoring",
    "2030: certification, EU launch"
  ],
  "safetyCompliancePoints": [
    "EU AI Act implementation, audit logs, provenance",
    "Safety guardrails (zones/contact force), HRI risk assessment",
    "Canary rollouts, tele‑assist, observability"
  ],
  "sensorsCompute": [
    "RGB‑D (e.g., Luxonis OAK‑D) + hand‑eye calibration",
    "LiDAR (Livox/Ouster) + 3D fusion (TSDF/Gaussian)",
    "Event cameras (proprio/high‑speed grasping)",
    "Tactile/FT sensors (BioTac, ATI Mini45) for grip evals",
    "Compute: NVIDIA Jetson Orin (Nano/AGX) + edge RTX; NVLink streaming",
    "End effectors: Robotiq/Schunk with force control, quick‑change"
  ],
  "stack": [
    "Python, ROS2 (rclcpp/rclpy), Nav2/MoveIt",
    "PyTorch/JAX, diffusion policies, VLM/VLA (OpenVLA, RT‑X)",
    "Isaac Lab/Sim, CuOpt, Triton Inference + TensorRT‑LLM",
    "LangGraph/agents, gRPC/event streams, Kafka/Redpanda",
    "Cloud‑native microservices (K8s), feature flags, canary"
  ],
  "standardsList": [
    "ISO 13482 (personal care robots)",
    "ISO 10218 / ISO/TS 15066 (collaborative robotics)",
    "CE directives & technical documentation"
  ],
  "timelinePhases": [
    {
      "items": [
        "AI framework, ROS2 integration, sim demonstrator"
      ],
      "period": "2025 – Foundations & prototyping"
    },
    {
      "items": [
        "Humanoid demonstrator, end‑to‑end tests"
      ],
      "period": "2026 – Integration & demo"
    },
    {
      "items": [
        "Everyday scenarios (grasping/assist), base models"
      ],
      "period": "2027 – Behaviors & everyday"
    },
    {
      "items": [
        "Developer SDK, billing/licensing"
      ],
      "period": "2028 – App store beta"
    },
    {
      "items": [
        "Fleet management, monitoring, updates"
      ],
      "period": "2029 – RaaS pilots"
    },
    {
      "items": [
        "CE/safety audits, market entry EU"
      ],
      "period": "2030 – Certification & EU launch"
    }
  ],
  "trl": {
    "target": "7–8",
    "today": 3
  },
  "workPackages": [
    {
      "deliverables": [
        "API docs",
        "v0.1 demo (motion+language)"
      ],
      "id": "WP1",
      "name": "Software framework for robot AI",
      "timeline": "2025"
    },
    {
      "deliverables": [
        "Integration study",
        "Live demo Q2 2026"
      ],
      "id": "WP2",
      "name": "Acquisition & integration of humanoid robots",
      "timeline": "2026"
    },
    {
      "deliverables": [
        "Datasets",
        "v1.0 base models"
      ],
      "id": "WP3",
      "name": "AI behavior modeling",
      "timeline": "2027"
    },
    {
      "deliverables": [
        "Beta platform",
        "Developer SDK"
      ],
      "id": "WP4",
      "name": "Platform 'Robot App Store'",
      "timeline": "2028"
    },
    {
      "deliverables": [
        "SaaS dashboard",
        "3 pilot projects"
      ],
      "id": "WP5",
      "name": "Robots‑as‑a‑Service (RaaS)",
      "timeline": "2029"
    },
    {
      "deliverables": [
        "Certification docs",
        "EU launch"
      ],
      "id": "WP6",
      "name": "Scaling & certification",
      "timeline": "2030"
    }
  ]
} as const;

export default data;
